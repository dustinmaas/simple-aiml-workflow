services:
  # InfluxDB - Time series database for network metrics
  influxdb:
    container_name: metrics_influxdb_test
    hostname: metrics_influxdb
    image: influxdb:2.7.1
    ports:
      - "8086:8086"
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=${INFLUXDB_USERNAME}
      - DOCKER_INFLUXDB_INIT_PASSWORD=${INFLUXDB_PASSWORD}
      - DOCKER_INFLUXDB_INIT_ORG=${INFLUXDB_ORG}
      - DOCKER_INFLUXDB_INIT_BUCKET=${INFLUXDB_BUCKET}
      - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=${INFLUXDB_ADMIN_TOKEN}
    volumes:
      - influxdb-data-test:/var/lib/influxdb2
    networks:
      - ai-ml-test-network
      - oran-sc-ric_ric_network
    healthcheck: &default-test-health-check
      test: ["CMD", "curl", "-f", "http://localhost:8086/health"]
      interval: 10s
      timeout: 2s
      retries: 3
      start_period: 10s

  # Model Server - Stores and serves PyTorch models
  model-server:
    build: ./model-server
    ports:
      - "5001:80"
    volumes:
      - ./model-server:/app
      - ./shared:/app/shared
      - model-data-test:/data/models
      - model-db-test:/data/db
    environment:
      - MODEL_SERVER_HOST=${MODEL_SERVER_HOST:-model-server}
      - MODEL_SERVER_PORT=${MODEL_SERVER_PORT:-80}
      - MODEL_STORAGE_DIR=${MODEL_STORAGE_DIR:-/data/models}
      - MODEL_DB_PATH=${MODEL_DB_PATH:-/data/db/models.db}
    networks:
      - ai-ml-test-network
    healthcheck:
      <<: *default-test-health-check
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 5s

  # Inference Server - Provides inference API for models
  inference-server:
    build: ./inference-server
    ports:
      - "5002:80"
    volumes:
      - ./inference-server:/app
      - ./shared:/app/shared
      - inference-cache-test:/app/cache/models
    depends_on:
      - model-server
    environment:
      - MODEL_SERVER_HOST=${MODEL_SERVER_HOST:-model-server}
      - MODEL_SERVER_PORT=${MODEL_SERVER_PORT:-80}
      - INFERENCE_SERVER_HOST=${INFERENCE_SERVER_HOST:-inference-server}
      - INFERENCE_SERVER_PORT=${INFERENCE_SERVER_PORT:-80}
      - MODEL_CACHE_DIR=${MODEL_CACHE_DIR:-/app/cache/models}
      - MAX_CACHE_SIZE=${MAX_CACHE_SIZE:-10}
    networks:
      - ai-ml-test-network
      - oran-sc-ric_ric_network
    healthcheck:
      <<: *default-test-health-check
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 5s

  # Analysis and Training Environment - Jupyter Lab for data analysis and model training
  analysis-and-training:
    build: ./analysis-and-training
    ports:
      - "8888:8888"
    volumes:
      - ./analysis-and-training:/app
    depends_on:
      - model-server
      - inference-server
    environment:
      - MODEL_SERVER_HOST=${MODEL_SERVER_HOST:-model-server}
      - MODEL_SERVER_PORT=${MODEL_SERVER_PORT:-80}
      - INFERENCE_SERVER_HOST=${INFERENCE_SERVER_HOST:-inference-server}
      - INFERENCE_SERVER_PORT=${INFERENCE_SERVER_PORT:-80}
    env_file:
      - .env
    networks:
      - ai-ml-test-network
      - oran-sc-ric_ric_network
    command: jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token=${JUPYTER_TOKEN}
    healthcheck:
      <<: *default-test-health-check
      test: ["CMD", "curl", "-f", "http://localhost:8888"]
      interval: 30s
      timeout: 5s

networks:
  ai-ml-test-network:
    driver: bridge
  oran-sc-ric_ric_network:
    external: true
    name: oran-sc-ric_ric_network

volumes:
  model-data-test:
    name: aiml-model-data-test
  model-db-test:
    name: aiml-model-db-test
  influxdb-data-test:
    name: aiml-influxdb-data-test
  inference-cache-test:
    name: aiml-inference-cache-test
