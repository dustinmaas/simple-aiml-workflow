{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "import requests\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968f16d9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from influxdb_client import InfluxDBClient\n",
    "\n",
    "# Connect to InfluxDB\n",
    "client = InfluxDBClient(url=\"http://10.0.2.25:8086\", token=\"ric_admin_token\", org=\"ric\")\n",
    "\n",
    "\n",
    "\n",
    "experiment_id = \"exp_1741030459\"\n",
    "# Query data\n",
    "query = '''\n",
    "from(bucket: \"network_metrics\")\n",
    "  |> range(start: -12h)\n",
    "  |> filter(fn: (r) => r.experiment_id == \"exp_1741030459\")\n",
    "  |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "  |> keep(columns: [\"timestamp\", \"ue_id\", \"atten\", \"min_prb_ratio\", \"CQI\", \"RSRP\", \"DRB.UEThpDl\", \"DRB.RlcSduTransmittedVolumeDL\"])\n",
    "'''\n",
    "\n",
    "result = client.query_api().query_data_frame(query=query)\n",
    "\n",
    "\n",
    "# Convert columns to appropriate data types\n",
    "result['ue_id'] = result['ue_id'].astype(int)\n",
    "result['atten'] = result['atten'].astype(int) \n",
    "result['min_prb_ratio'] = result['min_prb_ratio'].astype(int)\n",
    "result['CQI'] = result['CQI'].astype(int)\n",
    "result['RSRP'] = result['RSRP'].astype(int)\n",
    "result['DRB.UEThpDl'] = result['DRB.UEThpDl'].astype(float)\n",
    "result['DRB.RlcSduTransmittedVolumeDL'] = result['DRB.RlcSduTransmittedVolumeDL'].astype(float)\n",
    "result['timestamp'] = pd.to_datetime(result['timestamp'])\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = pd.DataFrame(result)\n",
    "df\n",
    "\n",
    "# Drop InfluxDB metadata columns\n",
    "df.drop(columns=['result', 'table'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc96ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in Mbps\n",
    "df['DRB.UEThpDl'] = df['DRB.UEThpDl'] / 1000.0\n",
    "df['DRB.RlcSduTransmittedVolumeDL'] = df['DRB.RlcSduTransmittedVolumeDL'] / 1000.0\n",
    "df.describe()\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dbf00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# grab ue1 data\n",
    "ue1_df = df[df['ue_id'] == 1].copy()\n",
    "\n",
    "# fix default min_prb_ratio at start (better to fix in experiment runner\n",
    "# ue1_df['min_prb_ratio'] = ue1_df['min_prb_ratio'].replace(0, 50)\n",
    "print(ue1_df.dtypes)\n",
    "ue1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b55ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ue1_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709fed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working on filtering out transient vals (not done)\n",
    "# ue1_df['min_thp_per'] = df.groupby('min_prb_ratio')['DRB.UEThpDl'].transform('min')\n",
    "# ue1_df[ue1_df['min_prb_ratio'] == 50]\n",
    "#ue1_df[ue1_df['DRB.UEThpDl'] == ue1_df['min_thp_per']].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d23c23f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# get a general idea of what the relevant data points look like\n",
    "# Create a Plotly time series figure for all metrics\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add each metric as a separate trace\n",
    "fig.add_trace(go.Scatter(x=ue1_df['timestamp'], y=ue1_df['atten'], mode='lines', name='atten'))\n",
    "fig.add_trace(go.Scatter(x=ue1_df['timestamp'], y=ue1_df['CQI'], mode='lines', name='CQI'))\n",
    "fig.add_trace(go.Scatter(x=ue1_df['timestamp'], y=ue1_df['RSRP'], mode='lines', name='RSRP'))\n",
    "fig.add_trace(go.Scatter(x=ue1_df['timestamp'], y=ue1_df['DRB.UEThpDl'], mode='lines', name='DRB.UEThpDl (Mbps)'))\n",
    "fig.add_trace(go.Scatter(x=ue1_df['timestamp'], y=ue1_df['min_prb_ratio'], mode='lines', name='min_prb_ratio'))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Time Series of Network Metrics',\n",
    "    xaxis_title='Timestamp',\n",
    "    yaxis_title='Value',\n",
    "    legend_title='Metrics',\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "# Add range slider\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=1, label=\"1h\", step=\"hour\", stepmode=\"backward\"),\n",
    "                dict(count=6, label=\"6h\", step=\"hour\", stepmode=\"backward\"),\n",
    "                dict(count=12, label=\"12h\", step=\"hour\", stepmode=\"backward\"),\n",
    "                dict(count=1, label=\"1d\", step=\"day\", stepmode=\"backward\"),\n",
    "                dict(step=\"all\")\n",
    "            ])\n",
    "        ),\n",
    "        rangeslider=dict(visible=True),\n",
    "        type=\"date\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b119ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tput vs. CQI and min prb ratio\n",
    "# note the transient values at the ratio switch points (95 -> 50 is the most egregious) \n",
    "# Create a function to make a scatter plot for a specific min_prb_ratio value\n",
    "def make_scatter_for_prb(df, prb_value):\n",
    "    df_filtered = df[df['min_prb_ratio'] == prb_value]\n",
    "    return go.Scatter(\n",
    "        x=df_filtered['CQI'],\n",
    "        y=df_filtered['DRB.UEThpDl'],\n",
    "        mode='markers',\n",
    "        name=f'min_prb_ratio = {prb_value}',\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            opacity=0.7,\n",
    "        ),\n",
    "        hovertemplate='CQI: %{x}<br>Throughput: %{y:.2f} Mbps<extra></extra>'\n",
    "    )\n",
    "\n",
    "# Get unique min_prb_ratio values\n",
    "unique_prb_values = sorted(ue1_df['min_prb_ratio'].unique())\n",
    "\n",
    "# Create subplot grid with one subplot per min_prb_ratio value\n",
    "fig = make_subplots(\n",
    "    rows=1, \n",
    "    cols=len(unique_prb_values),\n",
    "    subplot_titles=[f'min_prb_ratio = {val}' for val in unique_prb_values],\n",
    "    shared_yaxes=True\n",
    ")\n",
    "\n",
    "# Add a scatter trace for each min_prb_ratio value\n",
    "for i, prb_value in enumerate(unique_prb_values):\n",
    "    fig.add_trace(\n",
    "        make_scatter_for_prb(ue1_df, prb_value),\n",
    "        row=1, \n",
    "        col=i+1\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Throughput vs. CQI by min_prb_ratio',\n",
    "    height=500,\n",
    "    width=200 * len(unique_prb_values),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Update axes labels\n",
    "for i in range(len(unique_prb_values)):\n",
    "    fig.update_xaxes(title_text=\"CQI\", row=1, col=i+1)\n",
    "    if i == 0:  # Only add y-axis title to the first subplot\n",
    "        fig.update_yaxes(title_text=\"Throughput (Mbps)\", row=1, col=i+1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ca905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another view\n",
    "data = ue1_df[['CQI','DRB.UEThpDl', 'min_prb_ratio']]\n",
    "\n",
    "# Create a scatter matrix with Plotly\n",
    "# Use Plotly Express for pairplot equivalent\n",
    "fig = px.scatter_matrix(\n",
    "    data,\n",
    "    dimensions=[\"CQI\", \"DRB.UEThpDl\", \"min_prb_ratio\"],\n",
    "    color=\"DRB.UEThpDl\",\n",
    "    color_continuous_scale=px.colors.sequential.Viridis,\n",
    "    opacity=0.8,\n",
    "    title=\"Scatter Matrix (Pair Plot) of Network Metrics\"\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=800,\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "\n",
    "# Update traces\n",
    "fig.update_traces(\n",
    "    diagonal_visible=False,\n",
    "    showupperhalf=False,\n",
    "    marker=dict(size=5)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ff933",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "# print(f\"device {device}\")\n",
    "device = 'cpu'\n",
    "\n",
    "features = data[['CQI','DRB.UEThpDl']].values\n",
    "targets = data[['min_prb_ratio']].values\n",
    "\n",
    "\n",
    "# Convert features and targets to PyTorch tensors\n",
    "X = torch.tensor(features, dtype=torch.float32)\n",
    "y = torch.tensor(targets, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ac24c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(2, 1)  # two input features, one output feature\n",
    "        self.register_buffer('x_mean', torch.zeros(2))\n",
    "        self.register_buffer('x_std', torch.ones(2))\n",
    "        self.register_buffer('y_mean', torch.zeros(1))\n",
    "        self.register_buffer('y_std', torch.ones(1))\n",
    "\n",
    "    def forward(self, x: torch.Tensor, denormalize: bool = False) -> torch.Tensor:\n",
    "        x_scaled = (x - self.x_mean) / self.x_std\n",
    "        output = self.linear(x_scaled)\n",
    "        if denormalize == True:  # Explicit comparison for TorchScript compatibility\n",
    "            output = output * self.y_std + self.y_mean\n",
    "        return output\n",
    "    \n",
    "    # Add methods to make TorchScript serializable\n",
    "    def __getstate__(self):\n",
    "        return {\n",
    "            'linear.weight': self.linear.weight,\n",
    "            'linear.bias': self.linear.bias,\n",
    "            'x_mean': self.x_mean,\n",
    "            'x_std': self.x_std,\n",
    "            'y_mean': self.y_mean,\n",
    "            'y_std': self.y_std\n",
    "        }\n",
    "    \n",
    "    def __setstate__(self, state):\n",
    "        self.__init__()\n",
    "        self.linear.weight.data.copy_(state['linear.weight'])\n",
    "        self.linear.bias.data.copy_(state['linear.bias'])\n",
    "        self.x_mean.copy_(state['x_mean'])\n",
    "        self.x_std.copy_(state['x_std'])\n",
    "        self.y_mean.copy_(state['y_mean'])\n",
    "        self.y_std.copy_(state['y_std'])\n",
    "        \n",
    "    # Add a scripting method to convert the model to TorchScript\n",
    "    def to_torchscript(self):\n",
    "        self.eval()  # Set to evaluation mode\n",
    "        return torch.jit.script(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707999ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "model = LinearRegressionModel()\n",
    "model.x_mean = X.mean(dim=0, keepdim=True)\n",
    "model.x_std = X.std(dim=0, keepdim=True)\n",
    "model.y_mean = y.mean(dim=0, keepdim=True)\n",
    "model.y_std = y.std(dim=0, keepdim=True)\n",
    "model.to(device)\n",
    "X.to(device)\n",
    "y.to(device)\n",
    "criterion = torch.nn.MSELoss() # Mean Squared Error\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=.05)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    # Forward pass\n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted, (y - model.y_mean) / model.y_std)\n",
    "    # Backward and optimize\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4606df30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a temporary file\n",
    "model_id = \"linear_regression_v1\"\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "temp_model_path = os.path.join(temp_dir, f\"{model_id}.pt\")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Convert the model to TorchScript\n",
    "scripted_model = model.to_torchscript()\n",
    "\n",
    "# Save model\n",
    "scripted_model.save(temp_model_path)\n",
    "\n",
    "# Send to model server via REST API\n",
    "with open(temp_model_path, 'rb') as f:\n",
    "    files = {'model': f}\n",
    "    response = requests.post(f'http://model-server:5000/models/{model_id}', files=files)\n",
    "    \n",
    "if response.status_code == 200:\n",
    "    print(\"Model successfully uploaded to model server\")\n",
    "else:\n",
    "    print(f\"Error uploading model: {response.text}\")\n",
    "    \n",
    "# Cleanup temp file\n",
    "os.remove(temp_model_path)\n",
    "os.rmdir(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe739416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model from model server\n",
    "model_id = \"linear_regression_v1\"\n",
    "response = requests.get(f'http://model-server:5000/models/{model_id}')\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Create temp file to save the downloaded model\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    temp_model_path = os.path.join(temp_dir, f\"{model_id}.pt\")\n",
    "    \n",
    "    # Save the model to the temp file\n",
    "    with open(temp_model_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    # Load the checkpoint with the model\n",
    "    loaded_model = torch.jit.load(temp_model_path)\n",
    "    \n",
    "    # Verify model parameters\n",
    "    print(f\"Model ID: {model_id}\")\n",
    "    print(f\"X mean: {loaded_model.x_mean}\")\n",
    "    print(f\"X std: {loaded_model.x_std}\")\n",
    "    print(f\"Y mean: {loaded_model.y_mean}\")\n",
    "    print(f\"Y std: {loaded_model.y_std}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    os.remove(temp_model_path)\n",
    "    os.rmdir(temp_dir)\n",
    "    \n",
    "    print(\"Model successfully loaded from model server\")\n",
    "else:\n",
    "    print(f\"Error downloading model: {response.text}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62278e7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# generate some predictions across a range of input vals\n",
    "with torch.no_grad():\n",
    "    test_input = np.zeros((10 * 16, 2))\n",
    "    for ii in range(10):\n",
    "        test_input[ii * 16:ii * 16 + 16, 0] = ii + 6\n",
    "        test_input[ii * 16:ii * 16 + 16, 1] = np.arange(50, 210, 10)\n",
    "    test_input = torch.tensor(test_input, dtype=torch.float).to(device)\n",
    "    \n",
    "    # Make prediction with denormalization\n",
    "    predicted = loaded_model(test_input, denormalize=True)\n",
    "    \n",
    "    print(f'Predicted values:')\n",
    "    print(np.concatenate((test_input.cpu().numpy(), predicted.cpu().numpy()), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb933d34",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# look at the hyperplane fit\n",
    "\n",
    "# Get the learned parameters\n",
    "learned_weights = model.linear.weight.data.cpu().numpy()\n",
    "learned_bias = model.linear.bias.data.cpu().numpy()\n",
    "\n",
    "# Print the learned hyperplane equation (in scaled space)\n",
    "print(\"\\nLearned Hyperplane (in scaled space):\")\n",
    "print(f\"y_scaled = {learned_weights[0][0]:.2f}*x1_scaled + {learned_weights[0][1]:.2f}*x2_scaled + {learned_bias[0]:.2f}\")\n",
    "\n",
    "# Create scaled versions of features and targets using the model's normalization parameters\n",
    "features_scaled = (X.cpu().numpy() - model.x_mean.cpu().numpy()) / model.x_std.cpu().numpy()\n",
    "targets_scaled = (y.cpu().numpy() - model.y_mean.cpu().numpy()) / model.y_std.cpu().numpy()\n",
    "\n",
    "# Get original unscaled data\n",
    "features_unscaled = X.cpu().numpy()\n",
    "targets_unscaled = y.cpu().numpy()\n",
    "\n",
    "# Sample every 5th point for clarity in the scatter plot\n",
    "sample_indices = np.arange(0, len(features_unscaled), 5)\n",
    "features_sampled = features_unscaled[sample_indices]\n",
    "targets_sampled = targets_unscaled[sample_indices]\n",
    "\n",
    "# Create a meshgrid for the hyperplane using unscaled feature ranges\n",
    "x1_range = np.linspace(features_unscaled[:,0].min(), features_unscaled[:,0].max(), 20)\n",
    "x2_range = np.linspace(features_unscaled[:,1].min(), features_unscaled[:,1].max(), 20)\n",
    "X1, X2 = np.meshgrid(x1_range, x2_range)\n",
    "\n",
    "# Convert meshgrid to scaled space for prediction\n",
    "X1_scaled = (X1 - model.x_mean.cpu().numpy()[0, 0]) / model.x_std.cpu().numpy()[0, 0]\n",
    "X2_scaled = (X2 - model.x_mean.cpu().numpy()[0, 1]) / model.x_std.cpu().numpy()[0, 1]\n",
    "\n",
    "# Calculate predictions in scaled space\n",
    "Y_predicted_scaled = learned_weights[0][0] * X1_scaled + learned_weights[0][1] * X2_scaled + learned_bias[0]\n",
    "\n",
    "# Convert predictions back to unscaled space\n",
    "Y_predicted_unscaled = Y_predicted_scaled * model.y_std.cpu().numpy()[0, 0] + model.y_mean.cpu().numpy()[0, 0]\n",
    "\n",
    "# Create Plotly figure\n",
    "fig = make_subplots(rows=1, cols=1, specs=[[{'type': 'scene'}]])\n",
    "\n",
    "# Add scatter plot for data points\n",
    "scatter = go.Scatter3d(\n",
    "    x=features_sampled[:,0],\n",
    "    y=features_sampled[:,1],\n",
    "    z=targets_sampled.flatten(),\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='red',\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name='Data Points',\n",
    "    hovertemplate='CQI: %{x:.2f}<br>Throughput: %{y:.2f} Mbps<br>min_prb_ratio: %{z:.2f}<extra></extra>'\n",
    ")\n",
    "fig.add_trace(scatter)\n",
    "\n",
    "# Add surface plot for the hyperplane\n",
    "surface = go.Surface(\n",
    "    x=X1, \n",
    "    y=X2, \n",
    "    z=Y_predicted_unscaled,\n",
    "    colorscale='Blues',\n",
    "    opacity=0.7,\n",
    "    showscale=False,\n",
    "    name='Predicted Hyperplane',\n",
    "    hovertemplate='CQI: %{x:.2f}<br>Throughput: %{y:.2f} Mbps<br>Predicted min_prb_ratio: %{z:.2f}<extra></extra>'\n",
    ")\n",
    "fig.add_trace(surface)\n",
    "\n",
    "# Update layout with labels and title\n",
    "fig.update_layout(\n",
    "    title='Hyperplane Fit (Unscaled Values)',\n",
    "    scene=dict(\n",
    "        xaxis_title='CQI',\n",
    "        yaxis_title='DRB.UEThpDL (Mbps)',\n",
    "        zaxis_title='min_prb_ratio',\n",
    "        aspectmode='auto'\n",
    "    ),\n",
    "    legend=dict(\n",
    "        y=0.99,\n",
    "        x=0.01,\n",
    "        font=dict(size=12)\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=30),\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb0e951",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
