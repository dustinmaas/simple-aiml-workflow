{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4803b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "import os\n",
    "import tempfile\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94b0904",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from influxdb_client import InfluxDBClient\n",
    "\n",
    "# Connect to InfluxDB\n",
    "client = InfluxDBClient(url=\"http://10.0.2.25:8086\", token=\"ric_admin_token\", org=\"ric\")\n",
    "\n",
    "\n",
    "\n",
    "experiment_id = \"exp_1740883750\"\n",
    "# Query data\n",
    "query = '''\n",
    "from(bucket: \"network_metrics\")\n",
    "  |> range(start: -120h)\n",
    "  |> filter(fn: (r) => r.experiment_id == \"exp_1740883750\")\n",
    "  |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "  |> keep(columns: [\"timestamp\", \"ue_id\", \"atten\", \"min_prb_ratio\", \"CQI\", \"RSRP\", \"DRB.UEThpDl\", \"DRB.RlcSduTransmittedVolumeDL\"])\n",
    "'''\n",
    "\n",
    "result = client.query_api().query_data_frame(query=query)\n",
    "\n",
    "\n",
    "# Convert columns to appropriate data types\n",
    "result['ue_id'] = result['ue_id'].astype(int)\n",
    "result['atten'] = result['atten'].astype(int) \n",
    "result['min_prb_ratio'] = result['min_prb_ratio'].astype(int)\n",
    "result['CQI'] = result['CQI'].astype(int)\n",
    "result['RSRP'] = result['RSRP'].astype(int)\n",
    "result['DRB.UEThpDl'] = result['DRB.UEThpDl'].astype(float)\n",
    "result['DRB.RlcSduTransmittedVolumeDL'] = result['DRB.RlcSduTransmittedVolumeDL'].astype(float)\n",
    "result['timestamp'] = pd.to_datetime(result['timestamp'])\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = pd.DataFrame(result)\n",
    "df\n",
    "\n",
    "# Drop InfluxDB metadata columns\n",
    "df.drop(columns=['result', 'table'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67986921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in Mbps\n",
    "df['DRB.UEThpDl'] = df['DRB.UEThpDl'] / 1000.0\n",
    "df['DRB.RlcSduTransmittedVolumeDL'] = df['DRB.RlcSduTransmittedVolumeDL'] / 1000.0\n",
    "df.describe()\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeed875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# grab ue1 data\n",
    "ue1_df = df[df['ue_id'] == 1].copy()\n",
    "\n",
    "# fix default min_prb_ratio at start (better to fix in experiment runner\n",
    "# ue1_df['min_prb_ratio'] = ue1_df['min_prb_ratio'].replace(0, 50)\n",
    "print(ue1_df.dtypes)\n",
    "ue1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419415d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ue1_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e08aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working on filtering out transient vals (not done)\n",
    "# ue1_df['min_thp_per'] = df.groupby('min_prb_ratio')['DRB.UEThpDl'].transform('min')\n",
    "# ue1_df[ue1_df['min_prb_ratio'] == 50]\n",
    "#ue1_df[ue1_df['DRB.UEThpDl'] == ue1_df['min_thp_per']].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c045ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a general idea of what the relevant data points look like\n",
    "ue1_df.plot(x='timestamp', y=['atten', 'CQI', 'RSRP', 'DRB.UEThpDl', 'min_prb_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da31bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tput vs. CQI and min prb ratio\n",
    "# note the transient values at the ratio switch points (95 -> 50 is the most egregious) \n",
    "sns.relplot(data=ue1_df, x='CQI', y='DRB.UEThpDl', col='min_prb_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f852a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another view\n",
    "data = ue1_df[['CQI','DRB.UEThpDl', 'min_prb_ratio']]\n",
    "sns.pairplot(data=data, hue='DRB.UEThpDl')\n",
    "#sns.pairplot(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3a3ef",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "# print(f\"device {device}\")\n",
    "device = 'cpu'\n",
    "\n",
    "features = data[['CQI','DRB.UEThpDl']].values\n",
    "targets = data[['min_prb_ratio']].values\n",
    "\n",
    "\n",
    "# Convert features and targets to PyTorch tensors\n",
    "X = torch.tensor(features, dtype=torch.float32)\n",
    "y = torch.tensor(targets, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15421ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(2, 1)  # two input features, one output feature\n",
    "        self.register_buffer('x_mean', torch.zeros(2))\n",
    "        self.register_buffer('x_std', torch.ones(2))\n",
    "        self.register_buffer('y_mean', torch.zeros(1))\n",
    "        self.register_buffer('y_std', torch.ones(1))\n",
    "\n",
    "    def forward(self, x: torch.Tensor, denormalize: bool = False) -> torch.Tensor:\n",
    "        x_scaled = (x - self.x_mean) / self.x_std\n",
    "        output = self.linear(x_scaled)\n",
    "        if denormalize == True:  # Explicit comparison for TorchScript compatibility\n",
    "            output = output * self.y_std + self.y_mean\n",
    "        return output\n",
    "    \n",
    "    # Add methods to make TorchScript serializable\n",
    "    def __getstate__(self):\n",
    "        return {\n",
    "            'linear.weight': self.linear.weight,\n",
    "            'linear.bias': self.linear.bias,\n",
    "            'x_mean': self.x_mean,\n",
    "            'x_std': self.x_std,\n",
    "            'y_mean': self.y_mean,\n",
    "            'y_std': self.y_std\n",
    "        }\n",
    "    \n",
    "    def __setstate__(self, state):\n",
    "        self.__init__()\n",
    "        self.linear.weight.data.copy_(state['linear.weight'])\n",
    "        self.linear.bias.data.copy_(state['linear.bias'])\n",
    "        self.x_mean.copy_(state['x_mean'])\n",
    "        self.x_std.copy_(state['x_std'])\n",
    "        self.y_mean.copy_(state['y_mean'])\n",
    "        self.y_std.copy_(state['y_std'])\n",
    "        \n",
    "    # Add a scripting method to convert the model to TorchScript\n",
    "    def to_torchscript(self):\n",
    "        self.eval()  # Set to evaluation mode\n",
    "        return torch.jit.script(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a803605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "model = LinearRegressionModel()\n",
    "model.x_mean = X.mean(dim=0, keepdim=True)\n",
    "model.x_std = X.std(dim=0, keepdim=True)\n",
    "model.y_mean = y.mean(dim=0, keepdim=True)\n",
    "model.y_std = y.std(dim=0, keepdim=True)\n",
    "model.to(device)\n",
    "X.to(device)\n",
    "y.to(device)\n",
    "criterion = torch.nn.MSELoss() # Mean Squared Error\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=.05)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    # Forward pass\n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted, (y - model.y_mean) / model.y_std)\n",
    "    # Backward and optimize\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbbb7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a temporary file\n",
    "model_id = \"linear_regression_v1\"\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "temp_model_path = os.path.join(temp_dir, f\"{model_id}.pt\")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Convert the model to TorchScript\n",
    "scripted_model = model.to_torchscript()\n",
    "\n",
    "# Save model\n",
    "scripted_model.save(temp_model_path)\n",
    "\n",
    "# Send to model server via REST API\n",
    "with open(temp_model_path, 'rb') as f:\n",
    "    files = {'model': f}\n",
    "    response = requests.post(f'http://model-server:5000/models/{model_id}', files=files)\n",
    "    \n",
    "if response.status_code == 200:\n",
    "    print(\"Model successfully uploaded to model server\")\n",
    "else:\n",
    "    print(f\"Error uploading model: {response.text}\")\n",
    "    \n",
    "# Cleanup temp file\n",
    "os.remove(temp_model_path)\n",
    "os.rmdir(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6159f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model from model server\n",
    "model_id = \"linear_regression_v1\"\n",
    "response = requests.get(f'http://model-server:5000/models/{model_id}')\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Create temp file to save the downloaded model\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    temp_model_path = os.path.join(temp_dir, f\"{model_id}.pt\")\n",
    "    \n",
    "    # Save the model to the temp file\n",
    "    with open(temp_model_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    # Load the checkpoint with the model\n",
    "    loaded_model = torch.jit.load(temp_model_path)\n",
    "    \n",
    "    # Verify model parameters\n",
    "    print(f\"Model ID: {model_id}\")\n",
    "    print(f\"X mean: {loaded_model.x_mean}\")\n",
    "    print(f\"X std: {loaded_model.x_std}\")\n",
    "    print(f\"Y mean: {loaded_model.y_mean}\")\n",
    "    print(f\"Y std: {loaded_model.y_std}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    os.remove(temp_model_path)\n",
    "    os.rmdir(temp_dir)\n",
    "    \n",
    "    print(\"Model successfully loaded from model server\")\n",
    "else:\n",
    "    print(f\"Error downloading model: {response.text}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf48a0b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# generate some predictions across a range of input vals\n",
    "with torch.no_grad():\n",
    "    test_input = np.zeros((10 * 16, 2))\n",
    "    for ii in range(10):\n",
    "        test_input[ii * 16:ii * 16 + 16, 0] = ii + 6\n",
    "        test_input[ii * 16:ii * 16 + 16, 1] = np.arange(50, 210, 10)\n",
    "    test_input = torch.tensor(test_input, dtype=torch.float).to(device)\n",
    "    \n",
    "    # Make prediction with denormalization\n",
    "    predicted = loaded_model(test_input, denormalize=True)\n",
    "    \n",
    "    print(f'Predicted values:')\n",
    "    print(np.concatenate((test_input.cpu().numpy(), predicted.cpu().numpy()), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56774919",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# look at the poor hyperplane fit\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "# Get the learned parameters\n",
    "learned_weights = model.linear.weight.data.cpu().numpy()\n",
    "learned_bias = model.linear.bias.data.cpu().numpy()\n",
    "\n",
    "# Print the learned hyperplane equation (in scaled space)\n",
    "print(\"\\nLearned Hyperplane (in scaled space):\")\n",
    "print(f\"y_scaled = {learned_weights[0][0]:.2f}*x1_scaled + {learned_weights[0][1]:.2f}*x2_scaled + {learned_bias[0]:.2f}\")\n",
    "\n",
    "# Create scaled versions of features and targets using the model's normalization parameters\n",
    "features_scaled = (X.cpu().numpy() - model.x_mean.cpu().numpy()) / model.x_std.cpu().numpy()\n",
    "targets_scaled = (y.cpu().numpy() - model.y_mean.cpu().numpy()) / model.y_std.cpu().numpy()\n",
    "\n",
    "# Plot the data and the learned hyperplane using UNSCALED values\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Get original unscaled data\n",
    "features_unscaled = X.cpu().numpy()\n",
    "targets_unscaled = y.cpu().numpy()\n",
    "\n",
    "# Scatter plot of the unscaled data points (sampling every 5th point)\n",
    "ax.scatter(features_unscaled[::5,0], features_unscaled[::5,1], targets_unscaled[::5], \n",
    "           c='r', marker='o', s=2)\n",
    "\n",
    "# Create a meshgrid for the hyperplane using unscaled feature ranges\n",
    "x1_range = np.linspace(features_unscaled[:,0].min(), features_unscaled[:,0].max(), 20)\n",
    "x2_range = np.linspace(features_unscaled[:,1].min(), features_unscaled[:,1].max(), 20)\n",
    "X1, X2 = np.meshgrid(x1_range, x2_range)\n",
    "\n",
    "# Convert meshgrid to scaled space for prediction\n",
    "X1_scaled = (X1 - model.x_mean.cpu().numpy()[0, 0]) / model.x_std.cpu().numpy()[0, 0]\n",
    "X2_scaled = (X2 - model.x_mean.cpu().numpy()[0, 1]) / model.x_std.cpu().numpy()[0, 1]\n",
    "\n",
    "# Calculate predictions in scaled space\n",
    "Y_predicted_scaled = learned_weights[0][0] * X1_scaled + learned_weights[0][1] * X2_scaled + learned_bias[0]\n",
    "\n",
    "# Convert predictions back to unscaled space\n",
    "Y_predicted_unscaled = Y_predicted_scaled * model.y_std.cpu().numpy()[0, 0] + model.y_mean.cpu().numpy()[0, 0]\n",
    "\n",
    "# Plot the learned hyperplane in unscaled space\n",
    "surf = ax.plot_surface(X1, X2, Y_predicted_unscaled, alpha=0.5, color='blue')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('CQI')\n",
    "ax.set_ylabel('DRB.UEThpDL (Mbps)')\n",
    "ax.set_zlabel('min_prb_ratio')\n",
    "ax.set_title('Hyperplane Fit (Unscaled Values)')\n",
    "\n",
    "# Create a custom legend\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='r', markersize=8, label='Data Points'),\n",
    "    Patch(facecolor='blue', edgecolor='blue', alpha=0.5, label='Learned Hyperplane')\n",
    "]\n",
    "ax.legend(handles=legend_elements)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db01f6d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
